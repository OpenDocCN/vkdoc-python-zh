# 四、操作系统自动化

Python 最初是为了自动化一个叫做“变形虫”的分布式操作系统而构建的。尽管阿米巴操作系统几乎被遗忘了，但 Python 在自动化类 UNIX 操作系统任务方面找到了一个家。

Python 轻松地包装了传统的 UNIX C API，在使它们使用起来稍微安全一点的同时，给予运行 UNIX 的系统调用完全的访问权:这种方法被称为“带有泡沫填充物的 C”这种包装低级操作系统 API 的意愿使得它成为 UNIX shell 擅长的程序和 C 编程语言擅长的程序之间的一个很好的选择。

俗话说，权力越大，责任越大。为了考虑到程序员的能力和灵活性，Python 并不阻止程序员肆虐。小心翼翼地使用 Python 来编写工作的程序，更重要的是，以可预测的、安全的方式编写程序，这是一项值得掌握的技能。

## 4.1 文件

“一切都是文件”在 UNIX 上已经不是一个准确的咒语了。然而，许多东西都是文件，甚至更多的东西就像文件一样，用基于文件的系统调用来操作它们就足够了。

当处理文件内容时，Python 程序可以走两条路线中的一条。他们可以以“文本”或“二进制”格式打开它们尽管文件本身既不是文本也不是二进制文件，只是一个字节块，但打开模式很重要。

当以二进制格式打开文件时，字节以字节字符串的形式被读写。这对于非文本文件(如图片文件)非常有用。

当以文本形式打开文件时，必须使用*编码*。可以显式指定，但在某些情况下，会应用默认值。从文件中读取的所有字节都被解码，代码接收一个*字符*字符串。写入文件的所有字符串都被编码为字节。这意味着与文件的接口是字符串——字符序列。

二进制文件的一个简单例子是 GIMP“XCF”内部格式。GIMP 是一个图像处理程序，它以内部 XCF 格式保存文件，比图像有更多的细节。例如，为了便于编辑，XCF 中的图层将是独立的。

```py
>>> with open("Untitled.xcf", "rb") as fp:

...     header = fp.read(100)

```

这里我们打开一个文件。`rb`参数代表“读取，二进制”我们读取前一百个字节。我们将需要更少，但这通常是一个有用的策略。许多文件在开头都有一些元数据。

```py
>>> header[:9].decode('ascii')
'gimp xcf '

```

前九个字符实际上可以解码成 ASCII 文本，并且恰好是格式的名称。

```py
>>> header[9:9+4].decode('ascii')
'v011'

```

接下来的四个字符是版本。这个文件是 XCF 的第 11 个版本。

```py
>>> header[9+4]
0

```

0 字节结束“这是什么文件”元数据。这有各种好处。

```py
>>> struct.unpack('>I', header[9+4+1:9+4+1+4])
(1920,)

```

接下来的四个字节是宽度，以大端格式表示。`struct`模块知道如何解析这些。`>`表示它是大端字节序，`I`表示它是一个无符号的 4 字节整数。

```py
>>> struct.unpack('>I', header[9+4+1+4:9+4+1+4+4])
(1080,)

```

接下来的四个字节是宽度。这个简单的代码给了我们高层次的数据:它确认了这是 XCF，它显示了格式的版本，我们可以看到图像的尺寸。

以文本形式打开文件时，默认编码是 UTF-8。UTF-8 的一个优点是，它被设计成在某些东西不是 UTF-8 的情况下很快失败:它被精心设计成在先于 Unicode 的 ISO-8859-[1-9]上失败，以及在大多数二进制文件上失败。它还向后兼容 ASCII，这意味着纯 ASCII 文件仍然是有效的 UTF-8。

解析文本文件最流行的方式是逐行，Python 支持这种方式，让一个打开的文本文件成为一个迭代器，按顺序产生各行。

```py
>>> fp = open("things.txt", "w")

>>> fp.write("""\

... one line

... two lines

... red line

... blue line

... """)
39

>>> fp.close()

>>> fpin = open("things.txt")

>>> next(fpin)
'one line\n'

>>> next(fpin)
'two lines\n'

>>> next(fpin)
'red line\n'

>>> next(fpin)
'blue line\n'

>>> next(fpin)
Traceback (most recent call last):
  File "<stdin>", line 1, in <module>
StopIteration

```

通常我们不会直接调用`next`，而是使用`for`。此外，通常我们使用文件作为上下文管理器，以确保它们在一个很好理解的点关闭。然而，特别是在 REPL 场景中，有一个权衡:在没有上下文管理器的情况下打开文件允许我们探索阅读零碎的内容。

unix 系统上的文件不仅仅是数据块。它们附有各种元数据，可以查询，有时还可以更改。

`rename`系统调用被包装在`os.rename` Python 函数中。由于`rename`是原子的，这可以帮助实现需要特定状态的操作。

一般来说，注意到`os`模块倾向于是操作系统调用的一个薄薄的包装器。这里的讨论与类 UNIX 系统相关:Linux、基于 BSD 的系统，以及大多数情况下的 Mac OS X。这一点值得记住，但不值得指出我们做出特定于 UNIX 的假设的每个地方。

例如，

```py
with open("important.tmp", "w") as fout:
    fout.write("The horse raced past the barn")
    fout.write("fell.\n")
os.rename("important.tmp", "important")

```

这确保了在读取`important`文件时，我们不会意外地误解句子。如果代码中途崩溃，我们不会相信马跑过了谷仓，而是从`important`中一无所获。我们只在最后将`important.tmp`重命名为`important`，在最后一个字被写入文件之后。

在 UNIX 中，不是 blob 的文件的最重要的例子是目录。`os.makedirs`函数允许我们确保一个目录容易存在

```py
os.makedirs(some_path, exists_ok=True)

```

这与来自`os.path`的路径操作有力地结合起来，允许安全地创建嵌套文件:

```py
def open_for_write(fname, mode=""):
    os.makedirs(os.path.dirname(fname), exists_ok=True)
    return open(fname, "w" + mode)

with open_for_write("some/deep/nested/name/of/file.txt") as fp:
    fp.write("hello world")

```

例如，在镜像现有文件布局时，这可能会很有用。

`os.path`模块主要有字符串操作函数，这些函数假设字符串是文件名。`dirname`函数返回目录名，因此`os.path.dirname("a/b/c")`将返回`a/b`。类似地，函数`basename`返回“文件名”，因此`os.path.basename("a/b/c")`将返回`c`。两者的逆函数是`os.path.join`函数，它连接路径:`os.path.join("some", "long/and/winding", "path")`将返回`some/long/and/finding/path`。

`os.path`模块中的另一组函数对获取文件元数据进行了更高级别的抽象。值得注意的是，这些函数通常是操作系统功能的轻量级包装，并且*不会*试图隐藏操作系统的怪癖。这意味着操作系统的怪癖可以通过抽象“泄漏”。

最大的元数据是`os.path.exists`:文件存在吗？这有时会派上用场，尽管通常以不可知文件存在的方式编写代码会更好:文件存在可能会有竞争。更微妙的是`os.path.is...`函数:`isdir`、`isfile`、`islink`，更多的可以决定一个文件名是否指向我们所期望的。

`os.path.get...`函数获取非布尔元数据:访问时间、修改时间、c-time(有时简称为“创建时间”，但在一些微妙的情况下，这可能会引起误解，而不是实际的创建时间，更准确的说法是“i-node 修改时间”)，以及`getsize`获取文件的大小。

`shutil`模块(“shell 工具”)包含一些高级操作。`shutil.copy`将复制文件的内容和元数据。`shutil.copyfile`将只复制内容。`shutil.rmtree`相当于`rm -r`，而`shutil.copytree`相当于`cp -r`。

最后，临时文件通常很有用。Python 的`tempfile`模块产生安全且抗泄漏的临时文件。最有用的功能是`NamedTemporaryFile`，可以作为上下文使用。

典型的用法如下:

```py
with NamedTemporaryFile() as fp:
    fp.write("line 1\n")
    fp.write("line 2\n")
    fp.flush()
    function_taking_file_name(fp.name)

```

注意这里的`fp.flush`很重要。文件对象缓存写操作，直到关闭。但是，`NamedTemporaryFile`一关闭就会消失。在调用将重新打开文件进行读取的函数之前，显式刷新它是很重要的。

## 4.2 流程

Python 中处理运行子流程的主要模块是`subprocess`。它包含一个高级抽象，与大多数人想到“运行命令”时的直观模型相匹配，而不是在 UNIX 中使用`exec`和`fork`实现的低级模型。

它也是调用`os.system`函数的强大替代方法，后者在几个方面都有问题。例如，`os.system`产生了一个*额外的*进程，外壳。这意味着它依赖于 shell，在一些更奇怪的安装中，shell 可能与更“奇特”的系统 shell 不同，如`ash`或`fish`。最后，这意味着 shell 将*解析*字符串，这意味着字符串必须被正确序列化。这是一项艰巨的任务，因为 shell 解析器的正式规范很长。不幸的是，要写出在大多数情况下都能正常工作的东西并不困难，所以大多数错误都很微妙，并在最糟糕的时候出现。这有时甚至表现为安全缺陷。

虽然`subprocess`没有*完全*灵活，但是对于大多数需求，这个模块已经足够了。

`subprocess`本身也分为高层次的功能和低层次的实现层次。大多数情况下应该使用的高级函数是`check_call`和`check_output`。除了其他好处之外，它们的行为就像用`-e`或`set err`运行一个 shell 如果一个命令返回一个非零值，它们会立即引发一个异常。

稍微低一级的是`Popen`，它创建流程并允许对其输入和输出进行细粒度配置。`check_call`和`check_output`都是在`Popen`之上实现的。正因为如此，它们共享一些语义和论点。最重要的论点是`shell=True`，最重要的是，使用它几乎总是一个坏主意。当给定参数时，需要一个字符串，并将其传递给 shell 进行解析。

Shell 解析规则很微妙，充满了死角。如果它是一个常量命令，没有任何好处:我们可以将命令翻译成代码中的独立参数。如果它包含一些输入，那么几乎不可能以一种不引入注入问题的方式可靠地避开它。另一方面，如果没有这一点，即使面对潜在的恶意输入，即时创建命令也是可靠的。

例如，下面将把一个用户添加到 docker 组。

```py
subprocess.check_call(["usermod", "-G", "docker", "some-user"])

```

使用`check_call`意味着如果命令由于某种原因失败，比如用户不存在，这将自动引发一个异常。这避免了常见的失败模式，在这种模式下，脚本不会报告准确的状态。

如果我们想让它成为一个接受用户名的函数，这很简单:

```py
def add_to_docker(username):
    subprocess.check_call(["usermod", "-G", "docker", username])

```

请注意，即使参数包含空格、`#`或其他具有特殊含义的字符，调用它也是安全的。

为了判断当前用户当前在哪个组中，我们可以运行`groups`。

```py
groups = subprocess.check_output(["groups"]).split()

```

同样，如果命令失败，这将自动引发一个异常。如果成功，我们将得到字符串形式的输出:不需要手动读取和确定结束条件。

这两个函数有共同的参数。`cwd`允许在给定目录内运行命令。这对于在当前目录中查找的命令很重要。

```py
sha = subprocess.check_output(
          ["git", "rev-parse", "HEAD"],
          cwd="src/some-project").decode("ascii").strip()

```

这将获得项目的当前`git`散列，假设项目是 git 目录。如果不是这样，`git rev-parse HEAD`将返回非零值并引发一个异常。

注意，我们必须`decode`输出，因为`subprocess.check_output`像`subprocess`中的大多数函数一样，返回一个*字节字符串*，而不是一个 Unicode 字符串。在这种情况下，`rev-parse HEAD`总是返回一个十六进制字符串，所以我们使用了`ascii`编解码器。这对于任何非 ASCII 字符都将失败。

在某些情况下，使用高级抽象是不可能的。例如，用它们不可能发送标准输入或成块读取输出。

`Popen`运行子流程，允许对输入和输出进行精细控制。虽然所有的事情都有可能，但大多数事情都不容易做对。编写长管道的 shell 模式实现起来令人不快；更令人不快的是，要确保没有挥之不去的死锁条件；最重要的是，没有必要。

如果需要将短消息转换成标准输入，最好的方法是使用`communicate`方法。

```py
proc = Popen(["docker", "login", "--password-stdin"], stdin=PIPE)
out, err = proc.communicate(my_password + "\n")

```

如果需要更长的输入，让`communicate`在内存中缓冲可能会有问题。虽然可以以块的形式写入进程，但是在没有潜在死锁的情况下这样做是很重要的。最好的选择通常是使用临时文件:

```py
with tempfile.TemporaryFile() as fp:
    fp.write(contents)
    fp.write(of)
    fp.write(email)
    fp.flush()
    fp.seek(0)
    proc = Popen(["sendmail"], stdin=fp)
    result = proc.poll()

```

事实上，在这种情况下，我们甚至可以使用`check_call`函数:

```py
with tempfile.TemporaryFile() as fp:
    fp.write(contents)
    fp.write(of)
    fp.write(email)
    fp.flush()
    fp.seek(0)
    check_call(["sendmail"], stdin=fp)

```

如果您习惯于在 shell 中运行进程，那么您可能习惯于长管道:

```py
$ ls -l | sort | head -3 | awk '{print $3}'

```

如上所述，在 Python 中避免真正的命令并行性是一个最佳实践:在所有情况下，我们都试图在从下一个阶段读取之前完成一个阶段。在 Python 中，一般来说，使用`subprocess`只用于调用外部命令。对于输入的预处理和输出的后处理，我们通常使用 Python 的内置处理能力:在上面的例子中，我们将使用`sorted`切片和字符串操作来模拟逻辑。

用于文本和数字处理的命令在 Python 中很少有用，Python 有一个很好的内存模型来进行这种处理。在脚本中调用命令的一般情况是，操作数据的方式要么只记录为可由命令访问——例如，通过`ps -ef`查询过程，要么命令的替代方式是一个微妙的库，有时需要二进制绑定，例如在`docker`或`git`的情况下。

这是一个将 shell 脚本翻译成 Python 必须仔细考虑的地方。原始代码有一个依赖于通过`awk`或`sed`的特殊字符串操作的长管道，Python 代码可能不那么并行，而且更明显。需要注意的是，在这些情况下，翻译中会丢失一些东西:最初的低内存需求和透明并行。然而，作为回报，我们得到了更易维护和调试的代码。

## 4.3 联网

Python 有大量的网络支持。它从最底层开始:支持基于`socket`的系统调用到高层协议支持。解决问题的一些最佳方法是使用内置库。对于其他问题，最好的解决方案是第三方库。

底层网络 API 最直接的翻译在`socket`模块中。这个模块公开了`socket`对象。

HTTP 协议非常简单，因此我们可以直接从 Python 交互式命令提示符下实现一个简单的客户端。

```py
>>> import socket, json, pprint

>>> s = socket.socket()

>>> s.connect(('httpbin.org', 80))

>>> s.send(b'GET /get HTTP/1.0\r\nHost: httpbin.org\r\n\r\n')
40

>>> res = s.recv(1024)

>>> pprint.pprint(json.loads(

...               res.decode('ascii').split('\r\n\r\n', 1)[1]))
{'args': {},
 'headers': {'Connection': 'close', 'Host': 'httpbin.org'},
 'origin': '73.162.254.113',
 'url': 'http://httpbin.org/get'}

```

第`s = socket.socket()`行创建一个新的套接字*对象*。我们可以用套接字对象做很多事情。其中之一是将它们连接到一个端点:在本例中，连接到服务器 [`httpbin.org`](http://httpbin.org) ，端口 80。默认的套接字类型是一个*流*，*互联网*类型:这是 UNIX 引用 TCP 套接字的方式。

套接字连接后，我们可以向它发送字节。注意——在套接字上，只能发送字节串。我们读回结果并做一些特别的 HTTP 响应解析——并将实际内容解析为 JSON。

虽然一般来说，使用真正的 HTTP 客户端更好，但本文展示了如何编写低级套接字代码。这可能是有用的，例如，如果我们想通过重放确切的消息来诊断问题。

`socket` API 很微妙，上面的例子中有一些不正确的假设。在大多数情况下，这段代码可以工作，但是在遇到极端情况时会以奇怪的方式失败。

如果内部内核级发送缓冲区容纳不下所有数据，那么`send`方法可以不发送所有数据。这意味着它可以进行“部分发送”它返回上面的`40`，这是字节串的整个长度。正确的代码会检查返回值并发送剩余的块，直到什么都没有了。幸运的是，Python 已经有了一个方法:`sendall`。

然而，`recv`出现了一个更微妙的问题。它将返回与内核级缓冲区一样多的数据，因为它不知道另一端打算发送多少数据。同样，在大多数情况下，尤其是对于短消息，这将工作得很好。对于像 HTTP 1.0 这样的协议，正确的行为是一直读取，直到连接关闭。

下面是代码的一个固定版本:

```py
>>> import socket, json, pprint

>>> s = socket.socket()

>>> s.connect(('httpbin.org', 80))

>>> s.sendall(b'GET /get HTTP/1.0\r\nHost: httpbin.org\r\n\r\n')

>>> resp = b''

>>> while True:

...    more = s.recv(1024)

...    if more == b'':

...            break

...    resp += more

...

>>> pprint.pprint(json.loads(resp.decode('ascii').split('\r\n\r\n')[1]))
{'args': {},
 'headers': {'Connection': 'close', 'Host': 'httpbin.org'},
 'origin': '73.162.254.113',
 'url': 'http://httpbin.org/get'}

```

这是网络代码中的一个常见问题，在使用更高级别的抽象时也会发生。在简单的情况下，这些东西看起来可以工作，但在更极端的情况下，如高负载或网络拥塞时，它们就不能工作了。

有很多方法可以测试这些东西。其中之一是使用表现出极端行为的代理。编写或定制这些内容将需要使用`socket`的底层网络编码。

Python 也有更高层次的网络抽象。虽然`urllib`和`urllib2`模块是标准库的一部分，但是 web 上的最佳实践发展很快，一般来说，对于更高级别的抽象，第三方库通常更好。

其中最流行的是第三方库，`requests`。有了`requests`，获取一个简单的 HTTP 页面就简单多了。

```py
>>> import requests, pprint

>>> res=requests.get('http://httpbin.org/get')

>>> pprint.pprint(res.json())
{'args': {},
 'headers': {'Accept': '∗/∗',
             'Accept-Encoding': 'gzip, deflate',
             'Connection': 'close',
             'Host': 'httpbin.org',
             'User-Agent': 'python-requests/2.19.1'},
 'origin': '73.162.254.113',
 'url': 'http://httpbin.org/get'}

```

我们需要做的不是用原始字节制作自己的 HTTP 请求，而是给出一个 URL，类似于我们在浏览器中输入的 URL。请求解析它以找到要连接的主机( [`httpbin.org`](http://httpbin.org) )端口(80，默认为 HTTP)和路径(`/get`)。一旦收到响应，它会自动将其解析为头和内容，并允许我们以 JSON 的形式直接访问内容。

虽然`requests`很容易使用，但是，更好的方法是多花一点力气使用`Session`对象。否则，将使用默认会话。这导致代码具有非本地副作用:调用请求的一个子库改变了一些会话状态，这导致另一个子库的调用行为不同。例如，HTTP cookies 是在一个会话中共享的。

上面的代码最好写成:

```py
>>> import requests, pprint

>>> session = requests.Session()

>>> res = session.get('http://httpbin.org/get')

>>> pprint.pprint(res.json())
{'args': {},
 'headers': {'Accept': '∗/∗',
             'Accept-Encoding': 'gzip, deflate',
             'Connection': 'close',
             'Host': 'httpbin.org',
             'User-Agent': 'python-requests/2.19.1'},
 'origin': '73.162.254.113',
 'url': 'http://httpbin.org/get'}

```

在本例中，请求很简单，会话状态无关紧要。然而，这是一个需要养成的好习惯:即使在交互式解释器中，也要避免直接使用`get`、`put`和其他函数，而只使用会话接口。

使用交互式环境来构建代码原型是很自然的，这将在以后使其成为生产程序。通过保持这样的好习惯，我们可以轻松过渡。

## 4.4 总结

Python 是自动化操作系统操作的强大工具。这来自于拥有作为本机操作系统调用的瘦包装器的库和强大的第三方库的组合。

这允许我们接近操作系统，而没有任何介入的抽象，以及编写不关心这些无关紧要的细节的高级代码。

这种组合通常使 Python 成为编写脚本的更好选择，而不是使用 UNIX shell。这确实需要一种不同的思维方式:Python 并不适合文本转换器的长管道方法，但是在实践中，那些文本转换器的长管道结果是 shell 限制的产物。

使用现代的内存管理语言，将整个文本流读入内存通常更容易，然后操纵它，而不仅限于那些可以指定为管道的转换。