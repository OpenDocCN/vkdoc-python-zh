# 二、包

在现实世界中，处理 Python 的大部分工作都是处理第三方包。很长一段时间，情况都不好。然而，事情已经有了显著的改善。重要的是要理解哪些“最佳实践”是过时的惯例，哪些是基于错误的假设，但有一些优点，哪些实际上是好主意。

在处理包时，有两种交互方式。一种是成为“消费者”，希望使用软件包的功能。另一种是成为“制作人”，发布一个包。这些通常描述不同的开发任务，而不是不同的人。

在转向“生产”之前，对包的“消费者”方面有一个坚实的理解是很重要的如果包发布者的目标是对包用户有用，那么在开始写一行代码之前想象“最后一英里”是至关重要的。

## 2.1 点

Python 的基本打包工具是`pip`。默认情况下，Python 的安装不附带`pip`。这使得`pip`可以比核心 Python 运行得更快——并且可以与 PyPy 等替代 Python 实现一起工作。然而，它们确实带有有用的`ensurepip`模块。这允许通过`python -m ensurepip`获得 pip。这通常是引导`pip`的最简单方式。

一些 Python 安装，尤其是系统安装，会禁用`ensurepip`。当缺少`ensurepip`时，有一种手动获取的方式:`get-pip.py`。这是一个可下载的单个文件，当执行时，它将解包`pip`。

幸运的是，`pip`是唯一需要这些奇怪的旋转来安装的包。所有其他的包都可以并且应该使用`pip`来安装。这包括升级`pip`本身，可以用`pip install --upgrade pip`完成。

根据 Python 的安装方式，它的“真实环境”可能会也可能不会被我们的用户修改。各种自述文件和博客中的许多说明可能会鼓励进行 *sudo pip 安装*。这几乎总是错误的做法:它将在全局环境中安装软件包。

在虚拟环境中安装几乎总是更好，这些将在后面介绍。作为一种临时措施，也许是为了安装创建虚拟环境所需的东西，我们可以安装到我们的*用户*区域。这是用`pip install --user`完成的。

`pip install`命令将下载并安装所有依赖项。但是，它可能无法降级不兼容的软件包。总是可以安装显式版本:`pip install package-name==<version>`将安装这个精确的版本。这也是一个获得明确的非通用包的好方法，比如发布候选包、测试包或类似的包，用于本地测试。

如果安装了`wheel`，那么`pip`将为包构建轮子，通常是缓存轮子。这在处理高虚拟环境变动时特别有用，因为安装缓存轮是一个快速操作。这在处理所谓的“本机”或“二进制”包时也特别有用——那些需要用 C 编译器编译的包。轮缓存将消除再次构建轮缓存的需要。

`pip`确实允许卸载，带`pip uninstall`。默认情况下，该命令需要手动确认。除特殊情况外，不使用该命令。如果一个意想不到的包溜了进来，通常的反应是破坏环境并重建它。出于类似的原因，`pip install --ugprade`并不经常需要:常见的反应是破坏和重建环境。有一种情况是个好主意:`pip install --upgrade pip`。这是获得新版本`pip`的最好方法，它有错误修正和新特性。

`pip install`支持一个“需求文件”，`pip install --requirements`或`pip install -r`。一个需求文件每行只有一个包。这与在命令行上指定包没有什么不同。然而，需求文件经常指定“严格依赖”一个需求文件可以从`pip freeze`的环境中*生成*。获取需求文件的通常方法是，在虚拟环境中，执行以下操作:

```py
$ pip install -e .
$ pip freeze > requirements.txt

```

这意味着需求文件将拥有当前的包，以及它所有的递归依赖项，并有严格的版本。

## 2.2 虚拟环境

虚拟环境经常被误解，因为“环境”的概念并不清楚。Python 环境是指 Python 安装的根目录。它之所以重要是因为子目录`lib/site-packages`。`lib/site-packages`目录是安装第三方软件包的地方。在现代，它们经常被`pip`安装。虽然过去有其他工具可以做到这一点，但甚至自举`pip`和`virtualenv`都可以用`pip`来完成，更不用说日常的包管理了。

对于系统 Python 来说，唯一常见的选择是系统包。在 Anaconda 环境中，一些包可能作为 Anaconda 的一部分安装。事实上，这是 Anaconda 的一大好处:许多 Python 包都是定制的，尤其是那些构建起来不简单的包。

“真实的”环境是基于 Python 安装的环境。这意味着要获得一个新的真实环境，我们必须重新安装(通常是重建)Python。这有时是一个昂贵的提议。例如，如果任何参数不同，`tox`将从头开始重建环境。为此，*虚拟*环境存在。

虚拟环境从真实环境中复制最少的必要内容，误导 Python 认为它有了一个新的根。确切的细节并不重要，重要的是这是一个简单的命令，只是复制文件(有时使用符号链接)。

使用虚拟环境有两种方式:激活的和未激活的。为了使用在脚本和自动化过程中最常见的未激活的虚拟环境，我们从虚拟环境中显式调用 Python。

这意味着如果我们在`/home/name/venvs/my-special-env,`中创建了一个虚拟环境，我们可以调用`/home/name/venvs/my-special-env/bin/python`在这个环境中工作。例如，`/home/name/venvs/my-special-env/bin/python -m pip`将运行`pip`，但安装在虚拟环境中。注意，对于基于入口点的脚本，它们将与 Python 一起安装，所以我们可以运行`/home/name/venvs/my-special-env/bin/pip`在虚拟环境中安装包。

使用虚拟环境的另一种方法是“激活”它。在 bash-like shell 中激活虚拟环境意味着*为*提供激活脚本:

```py
$ source /home/name/venvs/my-special-env/bin/activate

```

sourcing 设置了几个环境变量，其中只有一个实际上是重要的。重要的变量是`PATH`，它以`/home/name/venvs/my-special-env/bin`为前缀。这意味着像`python`或`pip`这样的命令会首先出现在那里。有两个修饰性的变量被设定:`VIRTUAL_ENV`将指向环境的根源。这在希望了解虚拟环境的管理脚本中非常有用。

`PS1`将以`(my-special-env),`为前缀，这对于在控制台中交互工作时虚拟环境的视觉指示非常有用。

一般来说，在虚拟环境中只安装第三方软件包是一种好的做法。结合虚拟环境“廉价”的事实，这意味着如果一个人进入糟糕的状态，很容易删除整个目录并从头开始。例如，想象一个错误的包安装导致 Python 启动失败。即使运行`pip uninstall`也是不可能的，因为`pip`在启动时会失败。然而，“便宜”意味着我们可以移除整个虚拟环境，并用一组好的包重新创建它。

事实上，现代实践越来越倾向于将虚拟环境视为半不可变的:在创建它们之后，有一个“安装所有必需的包”的单一阶段如果需要升级，我们不是修改它，而是破坏环境，重新创建和重新安装。

创建虚拟环境有两种方式。一种方法是在 Python 2 和 Python 3 之间移植。这需要以某种方式引导，因为 Python 没有预装`virtualenv`。有几种方法可以实现这一点。如果 Python 是使用打包系统安装的，比如系统打包程序、Anaconda 或 Homebrew，那么通常同一个系统会打包`virtualenv`。如果 Python 是在用户目录中使用`pyenv`安装的，有时直接在“原始环境”中使用`pip install`是一个不错的选择，尽管这是“只安装到虚拟环境”的一个例外最后，这是`pip install --user`可能是个好主意的情况之一:这将把包安装到特殊的“用户区域”注意，这意味着有时它不在`$PATH`中，运行它的最佳方式是使用`python-m virtualenv.`

如果不需要可移植性，`venv`是一种创建虚拟环境的 Python 3 专用方法。它作为`python -m venv`被访问，因为没有专用的入口点。这解决了如何安装`virtualenv`的“引导”问题，尤其是在使用非系统 Python 时。

无论使用哪个命令来创建虚拟环境，它都会为该环境创建目录。最好是在此之前该目录不存在。最佳实践是在创建环境之前将其删除。还有关于如何创建环境的选项:使用哪个解释器和安装什么初始包。例如，有时完全跳过`pip`安装是有益的。然后我们可以通过使用`get-pip.py`在虚拟环境中引导`pip`。这是一种避免安装在真实环境中的`pip`的坏版本的方法——因为如果它足够坏，它甚至不能用于升级`pip`。

## 2.3 设置和车轮

术语“第三方”(如“第三方包”)是指除 Python 核心开发人员(“第一方”)或本地开发人员(“第二方”)之外的人。我们已经在安装部分介绍了如何安装“第一方”包。我们使用了`pip`和`virtualenv`来安装“第三方”包。是时候最终将我们的注意力转向缺失的环节了:本地开发和安装本地包，或者“第二方”包。

这是一个有很多新成员的领域，比如`pyproject.toml`和`flit`。然而，理解经典的做事方式是很重要的。首先，新的最佳实践需要一段时间来适应。另一方面，现有的实践是基于`setup.py`，因此这种方式在一段时间内仍将是主要方式——甚至可能是在可预见的未来。

文件用代码描述了我们的“发行版”请注意，“分发”不同于“打包”包是 Python 可以导入的(通常是)`__init__.py`的目录。一个发行版可以包含几个包，甚至不包含任何包！但是，保持 1-1-1 的关系是一个好主意:一个发行版，一个包，名称相同。

通常，`setup.py`会以导入`setuptools`或`distutils`开始。`distutils`是内置的，`setuptools`不是。然而，由于它非常受欢迎，它几乎总是首先安装在虚拟环境中。不推荐 Distutils:它已经很久没有更新了。请注意，`setup.py`不能有意义地、显式地声明它需要`setuptools`也不能显式地请求一个特定的版本:当它被读取时，它将已经试图导入`setuptools`。这种非声明性是包替代品的部分动机。

绝对有效的最低限度`setup.py`如下:

```py
import setuptools

setuptools.setup(
    packages=setuptools.find_packages(),
)

```

出于某种原因，官方文档称许多其他字段为“必需的”，尽管即使这些字段缺失，包也会被构建。对于一些人来说，这个*将会导致*产生难看的缺省值，比如包名是`UNKNOWN`。

当然，这些领域中有很多都是值得拥有的。但是这个框架`setup.py`足以创建一个包含目录中的本地 Python 包的发行版。

现在，当然，几乎总是会有其他领域需要添加。如果要将这个包上传到打包索引，即使它是一个私有索引，也必须添加其他字段。

添加至少一个“名称”字段是一个好主意。这将为发行版命名。如前所述，在发行版中以单个顶级包命名几乎总是一个好主意。

那么，典型的源层次结构将如下所示:

```py
setup.py
    import setuptools

    setuptools.setup(
        name='my_special_package',
        packages=setuptools.find_packages(),
    )
my_special_package/
    __init__.py
    another_module.py
    tests/
        test_another_module.py

```

另一个几乎总是好主意的领域是版本。软件版本化总是很难。尽管如此，即使是一个连续的数字，也是一个很好的方法来回答这个永恒的问题:“这是运行一个新的还是旧的版本？”

有一些工具可以帮助管理版本号，特别是假设我们希望在运行时 Python 也可以使用它。尤其是在进行日历版本管理时，`incremental`是一个强大的软件包，可以自动完成一些繁琐的工作。`bumpversion`是一个有用的工具，尤其是在选择语义版本化的时候。最后，`versioneer`支持与 git 版本控制系统的简单集成，所以发布只需要一个标签。

`setup.py`中的另一个流行字段是`install_requires`，它在文档中没有被标记为“required ”,但在几乎每个包中都存在。这就是我们如何标记代码使用的其他发行版。将“松散的”依赖关系放在`setup.py`中是一个很好的做法。这与指定特定版本的精确依赖相反。松散的依赖看起来像`Twisted>=17.5`——指定了最低版本，但没有最高版本。精确的依赖，像`Twisted==18.1`，在`setup.py`中通常是个坏主意。它们应该只在极端情况下使用:例如，当使用一个包的*私有* API 的重要部分时。

最后，给`find_packages`一个白名单，列出要包含的内容，以避免虚假文件，这是一个好主意。例如，

```py
setuptools.find_packages(include=["my_package∗"])

```

一旦我们有了`setup.py`和一些 Python 代码，我们想把它做成一个发行版。一个发行版可以有几种格式，但是我们这里要介绍的是*轮*。如果`my-directory`是有`setup.py`的那个，运行`pip wheel my-directory`，将产生一个轮子，以及它的所有递归依赖的轮子。

默认情况下，将轮子放在当前目录中，这很少是我们想要的行为。使用`--wheel-dir<output-directory>`将把轮子放到目录中——以及它所依赖的任何发行版的轮子。

我们可以用滚轮做几件事，但重要的是要注意我们可以做的一件事是`pip install <wheel file>`。如果我们添加了`pip install <wheel file> --wheel-dir <output directory>`，那么`pip`将使用目录中的轮子，而不会使用 PyPI。这对于可重复安装或支持气隙模式非常有用。

## 2.4 毒性

Tox 是一种自动管理虚拟环境的工具，通常用于测试和构建。它用于确保那些在定义良好的环境中运行，并智能地缓存它们以减少流失。Tox 作为一个测试运行工具，是按照*测试环境*配置的。

它使用一种独特的基于 ini 的配置格式。这使得编写配置变得困难，因为记住文件格式的微妙之处可能很难。然而，反过来，虽然很难利用，但是有很多能力可以帮助配置测试和构建清晰简洁的运行。

Tox 缺少的一点是构建步骤之间的依赖关系。这意味着这些通常是从外部管理的，通过在其他测试运行之后运行特定的测试运行，并以某种特别的方式共享工件。

Tox *环境*或多或少对应于配置文件中的一个部分。

```py
[testenv:some-name]

.
.
.

```

注意，如果名称包含`pyNM`(例如`py36`)，那么 Tox 将默认使用 CPython `N.M`(本例中为 3.6)作为该测试环境的 Python。如果名称包含`pypyNM,`，Tox 将默认使用 PyPy `N.M`作为该版本——其中这些代表“CPython 兼容性版本”,而不是 PyPy 自己的版本化方案。

如果名称不包含`pyNM`或`pypyNM`，或者如果需要覆盖缺省值，可以使用该部分中的`basepython`字段来表示特定的 Python 版本。默认情况下，Tox 将在路径中寻找这些蟒蛇。然而，如果安装了插件`tox-pyenv`，Tox 将查询`pyenv`是否在路径上找不到正确的 Python。

例如，我们将分析一个简单的 Tox 文件和一个更复杂的文件。

```py
[tox]
envlist = py36,pypy3.5,py36-flake8

```

`tox`部分是一个全局配置。在本例中，我们仅有的全局配置是环境列表。

```py
[testenv:py36-flake8]

```

这个部分配置`py36-flake8`测试环境。

```py
deps =
    flake8

```

`deps`小节详细说明了哪些包应该安装在测试环境的虚拟环境中。这里我们选择用一个松散的依赖关系来指定`flake8`。另一个选项是指定一个严格的依赖项(如`flake8==1.0.0.)`)。这有助于可重复的测试运行。我们也可以指定`-r <requirements file>`并单独管理需求。如果我们有接受需求文件的其他工具，这是很有用的。

```py
commands =
    flake8 useful

```

在这种情况下，唯一的命令是在目录`useful`上运行`flake8`。默认情况下，如果所有命令都返回成功的状态代码，Tox 测试运行将会成功。作为一个从命令行运行的程序，`flake8`尊重这个惯例，只有在代码没有问题的情况下，才会以一个成功的状态代码退出。

```py
[testenv]

```

缺少特定配置的其他两个环境将退回到通用环境。注意，由于它们的名字，它们将使用两种不同的解释器:兼容 Python 3.5 的 CPython 3.6 和 PyPy。

```py
deps =
    pytest

```

在这个环境中，我们安装了`pytest`转轮。注意，通过这种方式，我们的`tox.ini`记录了运行测试所需工具的假设。例如，如果我们的测试使用了`Hypothesis`或者`PyHamcrest`，这就是我们记录它的地方。

```py
commands =
    pytest useful

```

同样，命令运行很简单。再次注意，`pytest`遵守约定，只有在没有测试失败的情况下才会成功退出。

作为一个更现实的例子，我们转向`ncolony:`的`tox.ini`

```py
[tox]
envlist = {py36,py27,pypy}-{unit,func},py27-lint,py27-wheel,docs
toxworkdir = {toxinidir}/build/.tox

```

我们有更多的环境。注意，我们可以使用`{}`语法来创建一个环境矩阵。这意味着`{py36,py27,pypy}-{unit,func}`创造了`3*2=6`环境。请注意，如果我们有一个进行了“大跳跃”的依赖项(例如，Django 1 和 2)，并且我们想要对两者进行测试，我们可以对总共的`3*2*2=12`环境进行`{py36,py27, pypy}-{unit,func}-{django1,django2}`。请注意，像这样的矩阵测试的数字攀升很快——当使用自动化测试环境时，这意味着事情要么需要更长的时间，要么需要更高的并行性。

这是测试的全面性和资源使用之间的正常权衡。除了仔细考虑官方支持多少变种，没有什么神奇的解决方法。

```py
[testenv]

```

不是每个变体都有一个`testenv`，我们选择使用一个测试环境，但是通过匹配来特例化变体。这是创建许多测试环境变体的相当有效的方法。

```py
deps =
    {py36,py27,pypy}-unit: coverage
    {py27,pypy}-lint: pylint==1.8.1
    {py27,pypy}-lint: flake8
    {py27,pypy}-lint: incremental
    {py36,py27,pypy}-{func,unit}: Twisted

```

我们只在单元测试中需要`coverage`，而单元测试和功能测试都需要`Twisted`。`pylint`严格依赖确保了随着`pylint`添加更多的规则，我们的代码不会获得新的测试失败。这确实意味着我们需要不时地手动更新`pylint`。

```py
commands =
    {py36,py27,pypy}-unit: python -Wall \
                                  -Wignore::DeprecationWarning \
                                  -m coverage \
                                  run -m twisted.trial \
                                  --temp-directory build/_trial_temp \
                                  {posargs:ncolony}
    {py36,py27,pypy}-unit: coverage report --include ncolony∗ \
                           --omit ∗/tests/∗,∗/interfaces∗,∗/_version∗ \
↪                     --show-missing --fail-under=100
    py27-lint: pylint --rcfile admin/pylintrc ncolony
    py27-lint: python -m ncolony tests.nitpicker
    py27-lint: flake8 ncolony
    {py36,py27,pypy}-func: python -Werror -W ignore::DeprecationWarning \
                                  -W ignore::ImportWarning \
                                  -m ncolony tests.functional_test

```

配置“一个大的测试环境”意味着我们需要将所有的命令混合在一个包中，并基于模式进行选择。这也是一个更现实的测试运行命令——我们希望在启用警告的情况下运行，但是禁用我们不担心的警告，并且还启用代码覆盖测试。虽然具体的复杂性会有所不同，但我们几乎总是需要足够多的东西，以便命令能够增长到合适的大小。

```py
[testenv:py27-wheel]
skip_install = True

deps =
      coverage
      Twisted
      wheel
      gather
commands =
      mkdir -p {envtmpdir}/dist
      pip wheel . --no-deps --wheel-dir {envtmpdir}/dist
      sh -c "pip install --no-index {envtmpdir}/dist/∗.whl"
      coverage run {envbindir}/trial \
               --temp-directory build/_trial_temp {posargs:ncolony}
      coverage report --include ∗/site-packages/ncolony∗ \
                      --omit ∗/tests/∗,∗/interfaces∗,∗/_version∗ \
                      --show-missing --fail-under=100

```

测试运行确保我们可以制造和测试一个轮子。作为一个副作用，这意味着一个完整的测试运行将建立一个轮子。这允许我们在发布的时候上传一个测试过的轮到 PyPI。

```py
[testenv:docs]
changedir = docs
deps =
    sphinx
    Twisted
commands =
    sphinx-build -W -b html -d {envtmpdir}/doctrees . {envtmpdir}/html
basepython = python2.7

```

文档构建是 Tox 大放异彩的原因之一。它只在虚拟环境中安装`sphinx`用于构建文档。这意味着对`sphinx`未声明的依赖会使单元测试失败，因为`sphinx`没有安装在那里。

## 2.5 管道与诗歌

Pipenv 和 poem 是产生 Python 项目的两种新方法。它们分别受到 JavaScript 和 Ruby 的工具`yarn`和`bundler`的启发，这些工具旨在编码更完整的开发流程。就其本身而言，它们并不能替代 Tox——它们不能编码与多个 Python 解释器一起运行的能力，也不能完全覆盖依赖性。然而，可以将它们与 CI 系统配置文件(如`Jenkinsfile`或`.circleci/config.yml`)一起使用，以构建多种环境。

然而，它们的主要优势在于允许更容易的交互开发。有时，这对于更具探索性的编程很有用。

### 2.5.1 诗歌

安装诗歌最简单的方法就是使用`pip install --user poetry`。然而，这会将它的所有依赖项安装到您的用户环境中，这有可能把事情搞得一团糟。一种干净的方法是创建一个专用的虚拟环境。

```py
$ python3 -m venv ~/.venvs/poetry
$ ~/.venvs/poetry/bin/pip install poetry
$ alias poetry=~/.venvs/poetry/bin/poetry

```

这是一个使用*未激活的*虚拟环境的例子。

使用诗歌的最好方法是为项目创建一个专用的虚拟环境。我们将构建一个小型演示项目。我们称之为“有用”

```py
$ mkdir useful
$ cd useful
$ python3 -m venv build/useful
$ source build/useful/bin/activate
(useful)$ poetry init
(useful)$ poetry add termcolor
(useful)$ mkdir useful
(useful)$ touch useful/__init__.py
(useful)$ cat > useful/__main__.py
import termcolor
print(termcolor.colored("Hello", "red"))

```

如果我们做到了这一切，在虚拟环境中运行 *python -m 有用的*就会打印出红色的`Hello`。在我们交互式地尝试了各种颜色，并可能决定将文本加粗后，我们准备发布:

```py
(useful)$ poetry build
(useful)$ ls dist/
useful-0.1.0-py2.py3-none-any.whl useful-0.1.0.tar.gz

```

### 管道 nv

Pipenv 是一个创建符合规范的虚拟环境的工具，此外还有改进规范的方法。它依赖于两个文件:`Pipfile`和`Pipfile.lock`。我们可以像安装`poetry`一样安装`pipenv`，在定制的虚拟环境中添加一个别名。

为了开始使用它，我们希望确保没有虚拟环境被激活。然后，

```py
$ mkdir useful
$ cd useful
$ pipenv add termcolor
$ mkdir useful
$ touch useful/__init__.py
$ cat > useful/__main__.py
import termcolor
print(termcolor.colored("Hello", "red"))
$ pipenv shell
(useful-hwA3o_b5)$ python -m useful

```

这将在它后面留下一个看起来像这样的`Pipfile`:

```py
[[source]]
url = "https://pypi.org/simple"
verify_ssl = true
name = "pypi"

[packages]
termcolor = "∗"

[dev-packages]

[requires]
python_version = "3.6"

```

注意，为了封装`useful`，我们还是要写一个`setup.py`。Pipenv 将自己局限于管理虚拟环境，它确实考虑构建和发布单独的任务。

## 2.6 DevPI

DevPI 是一个 PyPI 兼容的服务器，可以在本地运行。虽然它不能扩展到类似 PyPI 的级别，但在许多情况下，它是一个强大的工具。

DevPI 由三部分组成。最重要的是`devpi-server`。对于许多用例来说，这是唯一需要运行的部分。服务器首先充当 PyPI 的缓存代理。它利用了 PyPI 上的包是*不可变的*的事实:一旦我们有了一个包，它就永远不会改变。

还有一个 web 服务器允许我们在本地包目录中进行搜索。由于许多用例甚至不涉及在 PyPI 网站上搜索，这肯定是可选的。最后，有一个客户机命令行工具，它允许在运行的实例上配置各种参数。客户端在更深奥的用例中最有用。

安装和运行 DevPI 非常简单。在虚拟环境中，只需运行:

```py
(devpi)$ pip install devpi-server
(devpi)$ devpi-server --start --init

```

默认情况下，`pip`工具转到`pypi.org`。对于 DevPI 的一些基本测试，我们可以创建一个新的虚拟环境`playground`，并运行:

```py
(playground)$ pip install \
              -i http://localhost:3141/root/pypi/+simple/ \
              httpie glom
(playground)$ http --body https://httpbin.org/get | glom '{"url":"url"}'
{
  "url": "https://httpbin.org/get"
}

```

每次都必须为`pip`指定`-i ...`参数会很烦人。在检查了一切都正常工作后，我们可以将配置放在一个环境变量中:

```py
$ export PIP_INDEX_URL=http://localhost:3141/root/pypi/+simple/

```

或者让事情变得更持久:

```py
$ mkdir -p ~/.pip && cat > ~/.pip/pip.conf << EOF
[global]
index-url = http://localhost:3141/root/pypi/+simple/

[search]
index = http://localhost:3141/root/pypi/

```

上述文件位置适用于 UNIX 操作系统。在 Mac OS X 上，配置文件是`$HOME/Library/Application Support/pip/pip.conf`。在 Windows 上，配置文件是`%APPDATA%\pip\pip.ini`。

DevPI 对于断开连接的操作很有用。如果我们需要在没有网络的情况下安装包，可以用 DevPI 来缓存。如前所述，虚拟环境是一次性的，通常被视为不可改变的。这意味着，如果没有网络，拥有正确软件包的虚拟环境*就不是*有用的东西。很有可能某种情况会要求或建议从头开始创建它。

然而，缓存服务器是另一回事。如果所有的包检索都是通过缓存代理完成的，那么破坏一个虚拟环境并重新构建它是没问题的，因为事实的来源是包缓存。这对于将笔记本电脑带进森林进行离线开发非常有用，对于维护适当的防火墙边界和拥有所有已安装软件的一致记录也非常有用。

为了“预热”DevPI 缓存，也就是确保它包含所有需要的包，我们需要使用`pip`来安装它们。一种方法是，在配置 DevPI 和`pip`之后，对正在开发的软件的源库运行`tox`。由于`tox`经历了所有的测试环境，它下载了所有需要的包。

在一次性虚拟环境中预装任何相关的`requirements.txt`，这绝对是一个好的做法。

然而，DevPI 的效用并不局限于断开连接的操作。在您的构建集群中配置一个，并将构建集群指向它，完全避免了“leftpad 事件”的风险，即您所依赖的包被作者从 PyPI 中删除。它也可能使构建更快，而且它肯定会减少大量的输出流量。

DevPI 的另一个用途是在上传到 PyPI 之前测试上传。假设`devpi-server`已经在默认端口上运行，我们可以:

```py
(devpi)$ pip install devpi-client twine
(devpi)$ devpi use http://localhost:3141
(devpi)$ devpi user -c testuser password=123
(devpi)$ devpi login testuser --password=123
(devpi)$ devpi index -c dev bases=root/pypi
(devpi)$ devpi use testuser/dev
(devpi)$ twine upload --repository http://localhost:3141/testuser/dev \
               -u testuser -p 123 my-package-18.6.0.tar.gz
(devpi)$ pip install -i http://localhost:3141/testuser/dev my-package

```

注意，这允许我们上传到一个我们只显式使用的索引，所以我们不会对所有没有显式使用它的环境隐藏`my-package`。

一个更高级的用例，我们可以这样做:

```py
(devpi)$ devpi index root/pypi mirror_url=https://ourdevpi.local

```

这将使我们的 DevPI 服务器成为本地“上游”DevPI 服务器的镜像。这允许我们将私有包上传到“中央”DevPI 服务器，以便与我们的团队共享。在这些情况下，上游 DevPI 服务器通常需要在代理服务器后面运行——我们需要一些工具来正确管理用户访问。

在一个要求用户名和密码的简单代理后面运行一个“集中式”DevPI 允许一个有效的私有存储库。为此，我们首先要删除`root/pypi`索引:

```py
$ devpi index --delete root/pypi

```

然后重新创建它

```py
$ devpi index --create root/pypi

```

这意味着根索引将不再镜像`pypi`。我们现在可以直接向它上传软件包。这种类型的服务器通常与参数`--extra-index-url`到`pip`一起使用，以允许`pip`从私有存储库和外部存储库中进行检索。然而，有时拥有一个只服务于特定包的`DevPI`实例是有用的。这允许在使用任何包之前执行关于审计的规则。每当需要一个新的包时，它就会被下载、审计，然后添加到私有存储库中。

## 2.7 Pex 和 Shiv

虽然目前将一个 Python 程序编译成一个自包含的可执行文件并不容易，但是我们可以做一些*几乎*一样好的事情。我们可以将一个 Python 程序编译成一个文件，只需要安装一个解释器就可以运行。这利用了 Python 处理启动的特殊方式。

运行`python /path/to/filename`时，Python 做两件事:

*   将目录`/path/to`添加到模块路径中。

*   执行`/path/to/filename`中的代码。

当运行`python/path/to/directory/`时，Python 的行为就像我们输入`python/path/to/directory/__main__.py`一样。

换句话说，Python 会做以下两件事:

*   将目录`/path/to/directory/`添加到模块路径中。

*   执行`/path/to/directory/__main__.py`中的代码。

运行`python /path/to/filename.zip`时，Python 会把文件当做一个目录。

换句话说，Python 会做以下两件事:

*   将【目录】添加到模块路径中。

*   执行从`/path/to/filename.zip`中提取的`__main__.py`中的代码。

Zip 是一种面向端的格式:元数据和指向数据的指针都在末尾。这意味着向 zip 文件添加前缀不会改变其内容。

因此，如果我们获取一个 zip 文件，并给它加上前缀`#!/usr/bin/python<newline>`，并将其标记为可执行，那么当运行它时，Python 将会运行一个 zip 文件。如果我们在`__main__.py`中放入正确的引导代码，并在 zip 文件中放入正确的模块，我们可以在一个大文件中获得我们所有的第三方依赖项。

Pex 和 Shiv 是生成这种文件的工具，但是它们都依赖于 Python 和 zip 文件的相同底层行为。

### 2.7.1 Pex

Pex 既可以用作命令行工具，也可以用作库。当使用它作为命令行工具时，防止它试图对 PyPI 进行依赖解析是一个好主意。所有的依赖关系解析算法在某些方面都有缺陷。然而，由于`pip`的流行，软件包将明确地解决其算法中的缺陷。Pex 不太受欢迎，不能保证软件包会明确地尝试使用它。

最安全的做法是使用`pip wheel`在一个目录中构建所有的轮子，然后告诉 Pex 只使用这个目录。

例如，

```py
$ pip wheel --wheel-dir my-wheels -r requirements.txt
$ pex -o my-file.pex --find-links my-wheels --no-index \
      -m some_package

```

Pex 有几种方法可以找到切入点。最受欢迎的两个是`-m some_package`，它会表现得像`python -m some_package`；或者是`-c console-script,`，它将找到作为`console-script`安装的脚本，并调用相关的入口点。

也可以使用 Pex 作为库。

```py
from pex import pex_builder

```

构建 Pex 文件的大部分逻辑都在`pex_builder`模块中。

```py
builder = pex_builder.PEXBuilder()

```

我们创建一个构建器对象。

```py
builder.set_entry_point('some_package')

```

我们设置了入口。这相当于命令行上的`-m some_package`参数。

```py
builder.set_shebang(sys.executable)

```

Pex 二进制有一个复杂的参数来确定正确的线。这有时是特定于预期的部署环境的，所以最好考虑一下正确的部署路线。一个选项是`/usr/bin/env python`，会找到当前 shell 调用的`python`。有时在这里指定一个版本是一个好主意，例如`/usr/local/bin/python3.6`。

```py
subprocess.check_call([sys.executable, '-m', 'pip', 'wheel',
                       '--wheel-dir', 'my-wheels',
                       '--requirements', 'requirements.txt'])

```

我们再次用`pip`创建轮子。尽管很诱人，`pip`不能作为库使用，所以 shelling out 是唯一支持的接口。

```py
for dist in os.listdir('my-wheels'):
    dist = os.path.join('my-wheels', dist)
    builder.add_dist_location(dist)

```

我们添加了`pip`构建的所有包。

```py
builder.build('my-file.pex')

```

最后，我们让构建器生成一个 Pex 文件。

### 2.7.2 刀

Shiv 是 Pex 背后相同理念的现代体现。但是，由于它直接使用了`pip`，它自己需要做的事情就少了很多。

```py
$ shiv -o my-file.shiv -e some_package -r requirements.txt

```

因为 shiv 只是卸载到 pip 实际依赖解析，所以直接调用它是安全的。Shiv 是 Pex 的年轻替代产品。这意味着很多糟粕已经被去除，但它仍然不够成熟。

例如，关于命令行参数的文档很少。目前也没有办法将它用作库。

## 2.8 XAR

XAR(可执行文件归档)是一种用于发布自包含可执行文件的通用格式。虽然不是特定于 Python 的，但它首先被设计为 Python。例如，它可以通过 PyPI 进行本地安装。

XAR 的缺点是，它假定了对`fuse`(用户空间中的文件系统)的某种程度的系统支持，而这种支持还不是通用的。如果所有设计用于运行 XAR、Linux 或 Mac OS X 的机器都在您的控制之下，这不是问题。关于如何安装适当的 FUSE 支持的说明并不复杂，但是它们需要管理权限。请注意，XAR 也没有 Pex 成熟。

然而，假设有适当的 SquashFS 支持，许多其他问题都会消失:包括，最重要的，与`pex`或`shiv`相比，本地 Python 版本。这使得 XAR 成为交付开发人员工具或本地系统管理脚本的有趣选择。

为了构建一个 XAR，如果安装了`xar`，我们可以用`bdist_xar`调用`setup.py`。

```py
python setup.py bdist_xar --console-scripts=my-script

```

在本例中，`my-script`是控制台脚本入口点的名称，在`setup.py`中用以下内容指定:

```py
entry_points=dict(
   console_scripts=["my-script = package.module:function"],
)

```

在某些情况下，`--console-scripts`参数是不必要的。如上例所示，如果只有一个控制台脚本入口点，那么它就是隐式的。否则，如果有一个与包同名的控制台脚本，则使用该脚本。这占了相当多的情况，也就是说这个论证往往是多余的。

## 2.9 摘要

Python 的强大之处很大程度上来自其强大的第三方生态系统:无论是对于数据科学还是网络代码，都有许多好的选择。理解如何安装、使用和更新第三方包对于用好 Python 至关重要。

对于私有包存储库，对内部库使用 Python 包，并以与开源库兼容的方式分发它们通常是个好主意。它允许使用相同的机制进行内部分发、版本控制和依赖性管理。